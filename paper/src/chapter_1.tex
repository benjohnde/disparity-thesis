\chapter{Introduction}
\label{chap:introduction}

\section{Motivation}

Computer vision establishes itself on the consumer market as more research is done.
The upcoming iPhone supports this as it will feature a dual camera system \footnote{\url{http://9to5mac.com/2016/02/03/sony-dual-cameras-iphone-7-plus/}, 2016-02-22.}.
In the year 2011 LG and HTC released the LG Optimus 3D\footnote{\url{https://en.wikipedia.org/wiki/LG_Optimus_3D} } and corresponding the HTC Evo 3D\footnote{\url{https://en.wikipedia.org/wiki/HTC_Evo_3D}}.
Both had a stereo camera implemented and an auto-stereoscopic display attached.
This enables one to view photos or videos taken in stereographic 3D without the actual need for additional peripheral like 3D glasses.
Both can be seen as an experiment as there was no big distribution, Apple normally focuses on the mainstream consumer market, opening up the box of possibilities and the need for such algorithms even further.
One example application for such a consumer-driven market could be the reconstruction of a face after taking a photo.
There exist no method to reconstruct a whole 3D model without having stereo images from all angles of the face, but it is possible to trick the user in having captured a 3D photo.
Another concrete example for an application regarding depth estimation in stereo videos is to detect moving people in a stereo video and calculate the distance to the camera of each person\footnote{\url{http://de.mathworks.com/help/vision/examples/depth-estimation-from-stereo-video.html}}.
\newline\newline\noindent Obtaining depth information as additional data to infer intents from human gestures has arrived in mainstream computing with the release of Kinect at November 4th, 2010.
Kinect is a hardware add-on for the Xbox video gaming console which enables users to interact visually with the console without actually using a controller or any other peripheral.
The Kinect for Xbox one utilizes two cameras, one capturing colored and the other monochrome images.
The monochrome sensor is used in combination with an infrared laser projector to obtain depth information via time of flight (TOF).
Time of flight is a method to measure the time light needs to reach objects and then to calculate the distance.
\newline\newline\noindent With deducing intents from human gestures a step in the field of artificial intelligence was made as the computer is now able to interpret human body language.
As this means processing an enormous stream of data (gathering and processing frame by frame) it represents a dataset of large and complex nature, also known as big data.
This also implies the need for new data processing techniques in comparison with traditional ones.
As a result one could say that computer vision is linked to both, artificial intelligence and big data.
New applications which arose from the combination of those topics are for instance:

\begin{itemize}
  \item robotic and autonomous driving,
  \item medical image analysis and automatic surgery,
  \item 3DTV and video compression.
\end{itemize}

\noindent Besides the technology of time of flight laser sensors - such as the Kinect\footnote{Besides the consumer market, for autonomous driving or robotic research Velodyne is a well-known sensor.} - there exists also the possibility to obtain depth information from stereo images by analyzing coherent images with so called disparity algorithms.
Thus, it is sufficient to have two calibrated aligned cameras (a stereo camera) to acquire disparity information and calculate the depth at each point.
But this leads to another fundamental problem of stereo matching: stereo correspondence.
Basically, stereo correspondence means the labelling of pixels, i.e. which pixel of the left image belongs to the corresponding pixel on the right image as a projection of the same three-dimensional point from the captured world, projected to the image plane in every image.
This problem of stereo correspondence has to be solved in order to actually match those and calculate the disparity.
According to \citeauthor{scharstein2002taxonomy}, stereo correspondence is one of the most heavily investigated topics in computer vision \citep{scharstein2002taxonomy}.
As there is still a lot of research going on, no algorithm is working without any mistakes and also the runtime is a bit quirky, Microsoft Kinect established itself as a real alternative.
This leads us to one of the disadvantages of Kinect sensor: Kinect is sensitive to other infrared sources (like sunlight) due to its nature of utilizing an infrared laser projector to acquire depth information, a stereo camera does not have this issue.
Although using two coherent images also have some disadvantages which will be discussed later on, it is an alternative way to receive depth information.
Especially thinking about autonomous driving during which at day a lot of sunlight is involved in, other techniques to estimate how far an object is away from one another are necessary to ensure a certain accuracy and fault-tolerance.

\section{Assignment}

The thesis' main goal is to provide an overview of selected disparity algorithms for stereoscopic videos and evaluate those.
\citeauthor{scharstein2002taxonomy} justified their tiny selection of disparity algorithms with the following: "Compiling a complete survey of existing stereo methods [...] would be a formidable task, as a large number of new methods are published every year." \citep{scharstein2002taxonomy}.
That said the ones with well documented source code and a research paper, also adaptable within the time scope of this thesis, were integrated.
The main assignments can be summarized in three research tasks:

\begin{itemize}
  \item Providing fundamental knowledge of existing stereo matching algorithms to have a basis for an advanced insight into the area of disparity algorithms targeting stereoscopic videos.
  \item Implementation of a stereo matcher for videos utilizing the OpenCV library. The implemented stereo matcher should be enhanced by using a spatiotemporal context
  \item Evaluation of the presented algorithms by implementation and presentation of an evaluation suite. Existing datasets, as well as a novel Dataset of the Department of Praktische Informatik IV\footnote{\url{http://ls.fmi.uni-mannheim.de/de/pi4/}} will thereby be examined using a set of defined quality metrics for assessment of the algorithms together with their runtime. Results are presented on a web-frontend.
\end{itemize}

\section{Outline}

The main purpose of Chapter \ref{chap:foundations} is to give an overview of terms and techniques used in this thesis.
The following Chapter \ref{chap:related} focuses more on disparity algorithms and related work.
To give an overview of state of the art algorithms a small summary of current used disparity algorithms is made.
This will create the foundations for the later implementation.
Chapter \ref{chap:impl} describes the implementation and explains reasons for building an evaluation engine.
The details of the implementation are explained afterwards.
In addition, the integration of existing algorithms is illustrated.
The evaluation engine was fed with datasets which are introduced in Chapter \ref{chap:eval}.
This chapter also explains the used quality metrics and describes the resulting outcome.
In the end, the results of this thesis are reflected in the concluding Chapter \ref{chap:conclusion}.
Besides some future work is pointed out.
